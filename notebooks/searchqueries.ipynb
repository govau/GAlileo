{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search query analysis\n",
    "\n",
    "## TODO\n",
    "* use part of speech to find all the verbs/nouns\n",
    "* use API search to find pages on domain and other domains on first page of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "import snowballstemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "from sklearn.cluster import AffinityPropagation, DBSCAN\n",
    "from collections import Counter, OrderedDict\n",
    "def find_modal_substring(strings):\n",
    "    from functools import partial, reduce\n",
    "    from itertools import chain\n",
    "    from typing import Iterator\n",
    "    \n",
    "\n",
    "    def ngram(seq: str, n: int) -> Iterator[str]:\n",
    "        return (seq[i: i+n] for i in range(0, len(seq)-n+1))\n",
    "\n",
    "    def allngram(seq: str, minn=1, maxn=None) -> Iterator[str]:\n",
    "        lengths = range(minn, maxn) if maxn else range(minn, len(seq))\n",
    "        ngrams = map(partial(ngram, seq), lengths)\n",
    "        return set(chain.from_iterable(ngrams))\n",
    "    \n",
    "    seqs_ngrams = map(partial(allngram), strings)\n",
    "    counts = Counter(chain.from_iterable(seqs_ngrams))\n",
    "    large_counts = {}\n",
    "    for sstr in counts:\n",
    "        key = counts[sstr]*len(sstr)\n",
    "        if len(sstr) > len(large_counts.get(key,\"\")):\n",
    "            large_counts[key] = sstr\n",
    "    largest_counts = dict(sorted(large_counts.items(),reverse=True))\n",
    "\n",
    "    modal_ngram = max(list(largest_counts.values())[:5], key=len).strip()\n",
    "    modal_words_search = re.search(r\"\\b.?\"+re.escape(modal_ngram)+r\".?\\b\",'\\n'.join(strings))\n",
    "    modal_words = modal_words_search.group(0).strip() if modal_words_search else None\n",
    "    if modal_words and modal_words.startswith(\".\"):\n",
    "        modal_words = modal_words[1:]\n",
    "    return modal_words or modal_ngram \n",
    "class LemmatizedTfidfVectorizer(TfidfVectorizer):\n",
    "    \"\"\"\n",
    "    Vectorizer that first lemmatizes words.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "      super().__init__(*args, **kwargs)\n",
    "      self.stemmer = snowballstemmer.stemmer('English')\n",
    "      \n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(LemmatizedTfidfVectorizer, self).build_analyzer()\n",
    "\n",
    "        def lemmatize(phrase):\n",
    "            words = analyzer(phrase)\n",
    "            return [self.stemmer.stemWord(word)\n",
    "                    for word in words]\n",
    "\n",
    "        return lemmatize\n",
    "    ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import random\n",
    "import re\n",
    "import glob\n",
    "from tablib import Dataset\n",
    "from urllib.parse import urlparse\n",
    "keywords = set()\n",
    "keywords_data = {}\n",
    "for filename in glob.glob('../data/searchqueries/*'):\n",
    "    print(filename)\n",
    "    imported_data = Dataset().load(open(filename).read())\n",
    "    for row in imported_data.dict:\n",
    "        query = row['query']\n",
    "        # remove single characters and lone numbers\n",
    "        query = \" \".join([x if len(x) > 1 and not x.isdigit() else \"\" for x in query.split(\" \")]).strip()\n",
    "        query = ''.join(e for e in re.sub(\"\\s\\s+\", \" \", query) if e.isalnum() or e == \" \" or e == \".\")\n",
    "        if query.startswith(\".\"):\n",
    "            query = query[1:]\n",
    "        # replace only number lines like phone numbers\n",
    "        if query.replace(\" \", \"\").strip().isdigit():\n",
    "            query = \"\"\n",
    "        if len(query) > 4:\n",
    "            if query not in keywords_data:\n",
    "                keywords_data[query] = {'clicks':0, 'impressions': 0, 'popularity': 0, 'pages': set()}\n",
    "            clicks = float(row.get('clicks',0)) if row.get('clicks','') != '' else 0\n",
    "            impressions = float(row.get('impressions',0)) if row.get('impressions','') != '' else 0\n",
    "            keywords_data[query]['clicks'] += clicks\n",
    "            keywords_data[query]['impressions'] += impressions\n",
    "            keywords_data[query]['popularity'] += impressions + clicks\n",
    "            if row.get('page'):\n",
    "                keywords_data[query]['pages'].add(urlparse(row.get('page')).hostname)\n",
    "            keywords.add(query)\n",
    "print(len(keywords))\n",
    "print(list(keywords)[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "stop_words= ENGLISH_STOP_WORDS.union(\n",
    "    ['australia','australian','government','of',\"www\",\"gov\",\"au\",\"have\",\"any\"])\n",
    "vec = LemmatizedTfidfVectorizer(stop_words=stop_words)\n",
    "vectorized = vec.fit_transform(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#af = AffinityPropagation(max_iter=2, convergence_iter=2).fit(vectorized)\n",
    "clustering = DBSCAN(eps=0.5, min_samples=2).fit(vectorized)\n",
    "# import hdbscan\n",
    "# clusterer = hdbscan.HDBSCAN()\n",
    "# clustering = clusterer.fit(vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "stop_words = ENGLISH_STOP_WORDS.union(\n",
    "    [])\n",
    "clusters = {}\n",
    "labelled_clusters = {}\n",
    "cluster_data = {}\n",
    "for keyword, cluster_id in zip(keywords, clustering.labels_):\n",
    "    clusters.setdefault(cluster_id, []).append(keyword)\n",
    "print(len(clusters),\"clusters\",\"\\n\")\n",
    "i = 0\n",
    "for id, items in clusters.items():\n",
    "   \n",
    "    if len(items) > 4 and len(items) < 100:\n",
    "        i += 1\n",
    "        clean_items = []\n",
    "        data = { 'total_clicks':0, 'total_impressions': 0, 'total_popularity': 0, 'pages': set()}\n",
    "        for item in items:\n",
    "            #word_tokens = word_tokenize(item) \n",
    "            data['total_clicks'] += keywords_data.get(item,{}).get('clicks',0)\n",
    "            data['total_impressions'] += keywords_data.get(item,{}).get('impressions',0)\n",
    "            data['total_popularity'] += keywords_data.get(item,{}).get('popularity',0)\n",
    "            if keywords_data.get(item,{}).get('pages'):\n",
    "                data['pages'].update(keywords_data.get(item,{}).get('pages')) \n",
    "            word_tokens = item.lower().split(\" \")\n",
    "            clean_items.append(\" \".join([lemmatizer.lemmatize(w) for w in word_tokens if not w in stop_words]))\n",
    "        title = find_modal_substring(clean_items)\n",
    "        if len(title) < 3:\n",
    "            title = items[0]\n",
    "        labelled_clusters[title]=sorted(items)\n",
    "        cluster_data[title] = data\n",
    "print(\"displayed\",i,\"clusters\")\n",
    "ordered_clusters = OrderedDict(sorted(labelled_clusters.items(), key=lambda t: t[0])).items()\n",
    "top_clusters_titles = sorted(labelled_clusters, key=lambda t: cluster_data[t]['total_impressions'], reverse=True)\n",
    "for label in top_clusters_titles[:10]:\n",
    "     print(\"# \",label)\n",
    "     print(cluster_data[label]['pages'])\n",
    "     print('\\n'.join(labelled_clusters[label]))\n",
    "     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import string\n",
    "from yattag import Doc, indent\n",
    "\n",
    "doc, tag, text = Doc().tagtext()\n",
    "header=\"\"\"\n",
    "\n",
    "<html>\n",
    "  <head>\n",
    "    <link rel=\"stylesheet\" href=\"https://designsystem.gov.au/assets/css/style.css\" />\n",
    "    <style>\n",
    "    .keyword {\n",
    "\n",
    "  padding-bottom: 20px;\n",
    "}\n",
    ".keyword ul {\n",
    "margin-top: 0 !important;\n",
    "      column-count: 3;\n",
    "  column-gap: 40px;\n",
    "  column-fill: balance-all;\n",
    "  column-rule: 1px solid black;\n",
    "      padding-bottom: 5px;\n",
    "}\n",
    ".keyword li {\n",
    "    break-inside: avoid-column;\n",
    "    -webkit-column-break-inside: avoid;\n",
    "}\n",
    ".keyword h3 {\n",
    "  -webkit-column-span: all; /* Chrome, Safari, Opera */\n",
    "  column-span: all;\n",
    "}\n",
    "    </style>\n",
    "  </head>\n",
    "  <body class=\"au-grid au-body\">\n",
    "  <header class=\"au-header au-header--dark\" role=\"banner\">\n",
    "    <div class=\"container\">\n",
    "        <div class=\"row\">\n",
    "            <div class=\"col-md-9\">\n",
    "                <a class=\"au-header__brand\" href=\"#\">\n",
    "                    <img\n",
    "                            class=\"au-header__brand-image\"\n",
    "                            alt=\"Australian Government\"\n",
    "                            src=\"https://designsystem.gov.au/assets/img/header-logo-agov.png\"\n",
    "                    />\n",
    "                    <div class=\"au-header__text\">\n",
    "                        <h1 class=\"au-header__heading\">Observatory</h1>\n",
    "                        <div class=\"au-header__subline\">\n",
    "                            To quantify interactions with every government service\n",
    "                        </div>\n",
    "                    </div>\n",
    "                </a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    <br/>\n",
    "</header>\n",
    "  \t<main id=\"content\"  class=\"au-body\">\n",
    "\t\t<!--CONTENT-->\n",
    "\t\t<section>\n",
    "\t\t\t<div class=\"container-fluid\">\n",
    "\t\t\t\t<div class=\"row\">\n",
    "\"\"\"\n",
    "footer=\"\"\"\n",
    "</div></section>\n",
    "<footer\n",
    "        class=\"au-footer footer au-body au-body--dark au-footer--dark \"\n",
    "        role=\"contentinfo\"\n",
    ">\n",
    "    <div class=\"container-fluid\">\n",
    "        <nav class=\"au-footer__navigation \" aria-label=\"footer\">\n",
    "            <div class=\"col-md-offset-1 col-md-8 col-md-push-3\">\n",
    "\n",
    "                <ul class=\"au-link-list  au-link-list--inline\">\n",
    "                    <li><a href=\"/support\">About the Observatory</a></li>\n",
    "                    <li>\n",
    "                        <a href=\"https://www.dta.gov.au/privacy-statement\">Privacy</a>\n",
    "                    </li>\n",
    "                    <li><a href=\"/support\">Training and Support</a></li>\n",
    "                    <li><a href=\"/support\">Contact</a></li>\n",
    "                </ul>\n",
    "                <div class=\"au-footer__end\">\n",
    "                    <div class=\"footer__content footer__legal\">\n",
    "                        <p>\n",
    "                            © Commonwealth of Australia. With the exception of the\n",
    "                            Commonwealth Coat of Arms and where otherwise noted, this work\n",
    "                            is licensed under the\n",
    "                            <a\n",
    "                                    href=\"https://github.com/govau/design-system-components/blob/master/LICENSE\"\n",
    "                                    rel=\"external\"\n",
    "                            >MIT license</a\n",
    "                            >\n",
    "                        </p>\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "            <div class=\"col-md-3 col-md-pull-9 footer__logo\">\n",
    "                <p class=\"footer__affiliate\">\n",
    "              <span>An initiative of the </span\n",
    "              ><span>Digital Transformation Agency </span\n",
    "                ><span class=\"footer__affiliate-link\"\n",
    "                ><a\n",
    "                        class=\"au-cta-link  au-cta-link--dark\"\n",
    "                        href=\"https://www.dta.gov.au/our-projects\"\n",
    "                >More projects</a\n",
    "                ></span\n",
    "                >\n",
    "                </p>\n",
    "            </div>\n",
    "        </nav>\n",
    "    </div>\n",
    "</footer>\n",
    "</main>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "with tag('div', klass=\"col-md-12\"):\n",
    "    doc.stag('br')\n",
    "    with tag('h1'):\n",
    "        text(\"Search Queries\")\n",
    "    with tag('section', klass='au-callout'):\n",
    "        text('Browse search queries that lead to government websites grouped by letter and a common keyword')\n",
    "    with tag('p', id='letters'):\n",
    "        with tag(\"h2\"):\n",
    "            text(\"Jump to letter\")\n",
    "        for letter in ['2','3']+[x for x in string.ascii_lowercase if x not in ['x','z']]:\n",
    "            with tag('a', href=\"#\"+letter):\n",
    "                text(letter)\n",
    "    with tag('p', id='letters'):\n",
    "        with tag(\"h2\"):\n",
    "            text(\"Jump to popular search query\")\n",
    "        for query in top_clusters_titles[:10]:\n",
    "            with tag('a', href=\"#\"+query):\n",
    "                text(query)\n",
    "    last_letter=' '\n",
    "    i = 0\n",
    "    for title, cluster in ordered_clusters:\n",
    "        letter = title[0]\n",
    "        if letter != last_letter:\n",
    "            if i > 0:\n",
    "                with tag('small'):\n",
    "                    text(\"(%s keywords starting with '%s')\"%(i,last_letter))\n",
    "            i = 0\n",
    "            doc.stag('hr')\n",
    "        i += 1\n",
    "        #print(title)\n",
    "        #print(last_letter)\\\n",
    "        if letter != last_letter:\n",
    "            with tag('a',id = letter):\n",
    "                text(\"\")\n",
    "            with tag('h2'):\n",
    "                text(letter)\n",
    "        with tag('div', klass=\"keyword\"):\n",
    "            total_clicks = 0\n",
    "            total_impressions = 0\n",
    "            total_popularity = 0\n",
    "            with tag('a', id=title):\n",
    "                text('')\n",
    "            with tag('h3'):\n",
    "                    text(title)\n",
    "            with tag(\"ul\"):\n",
    "                for item in cluster:\n",
    "                    if len(cluster) < 25 or keywords_data.get(item,{}).get('popularity',0) / cluster_data[title]['total_popularity'] > 0.01:\n",
    "                        with tag(\"li\"):\n",
    "                            with tag(\"abbr\", \n",
    "                                     title=\"%s clicks, %s impressions\"%\n",
    "                                     (keywords_data.get(item,{}).get('clicks',0), \n",
    "                                      keywords_data.get(item,{}).get('impressions',0))):\n",
    "                                text(item)\n",
    "            with tag(\"small\"):\n",
    "                text(\"%s variations, %s clicks, %s impressions, appears on %s\" %(len(cluster),\n",
    "                                                                  cluster_data[title]['total_clicks'],\n",
    "                                                                  cluster_data[title]['total_impressions'],\n",
    "                                                                            ' and '.join(list(cluster_data[title]['pages']))))\n",
    "                doc.stag('br')\n",
    "                with tag('a', id=title, href='#'+title):\n",
    "                    text('[link]')\n",
    "        if letter != last_letter:\n",
    "            last_letter = title[0]\n",
    "    if i > 0:\n",
    "        with tag('small'):\n",
    "            text(\"(%s keywords starting with '%s')\"%(i,last_letter))\n",
    "    with tag('div'):\n",
    "        text('')\n",
    "with open('search-queries.html','wt') as out:\n",
    "    out.write(header)\n",
    "    out.write(indent(doc.getvalue()))\n",
    "    out.write(footer)\n",
    "    print(\"exported search-queries.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
